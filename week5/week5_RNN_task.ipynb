{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitaRamo/deep_learning_coursera/blob/master/week5_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LAZmZTpIb9cZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "O2ivZKXkc_ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "06a6de00-9789-4e7e-f475-7e2ade481b7d"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-27 15:47:17--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-27 15:47:17 (40.1 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "OxjXzyq_b9cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dda7a04-c829-46d7-bd75-15ad7b737109"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCwORD3Ub9cn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "-dK5iSs4b9cq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "dca-mF_qb9cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "cba2b75c-7416-47bd-c57a-17ec215919d4"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "LXvTFd-ab9c0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "071d9c88-6668-4c6b-cb14-36408a6184f0"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fca0b0815c0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NrDd1EVHb9c4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "AEvEjj2Vb9c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cccf36bc-1420-463b-8677-166b74f51f7b"
      },
      "cell_type": "code",
      "source": [
        "tokens = set(\" \".join(names)+pad_token) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e9QUTQ3Qb9c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "ToRr2VCFb9dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id =  dict(zip(tokens,range(n_tokens)))### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "0B_tzaoHb9dD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros((len(names), max_len), dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "EXMxJx-kb9dH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "55f071d2-7e6a-4e57-8b3d-235243b0b3b6"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0 20 54 25 32 25 11  6 33]\n",
            " [ 0 19  6 24 47 34 33 33 33]\n",
            " [ 0 31 47 29 48 48 29 11 33]\n",
            " [ 0 19 29 24  5 25  7  7 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nQylcwtzb9dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "Sl8b08Whb9dO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "QB5ZYJ1Bb9dT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation=\"elu\")\n",
        "\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fepr0outb9dW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "QzJIY6pHb9dX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t] ,1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next =  get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTnzb-l7b9dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "CsSyWhZfb9dd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVqjLYVOb9dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "Cqs2TS4xb9di",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G1UL6ZZXb9dl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "Df8ONkFwb9dn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8zt46mbb9dr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "dxO-VsZsb9dt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "bca42e5a-d33a-40cc-af35-c3808f12d782"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fca09213630>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "luikiVIDb9d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "x1bDmygpb9d1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "Au0yOCFZb9d5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "BOdV8eItb9d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "b129f88d-fa14-4e2e-cc97-b52efb285402"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Kara\n",
            " Skainyn\n",
            " Smenly\n",
            " Elly\n",
            " AlAna\n",
            " Ronet\n",
            " Reebe\n",
            " Prela\n",
            " Bred\n",
            " Pinlil\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "M0XXoPAHb9eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "63628692-783e-45a3-a692-cebe22ad43fb"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Leo'))"
      ],
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Leobrste\n",
            " Leon\n",
            " Leonfaden\n",
            " Leoborny\n",
            " Leodoe\n",
            " Leonte\n",
            " Leonmy\n",
            " Leonalen\n",
            " Leone\n",
            " Leog\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FCDojRtAb9eD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "Zx09BHiHb9eE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"7yAtCj1NWECWCoTZ\"\n",
        "COURSERA_EMAIL = \"rita.mparada.ramos@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "qpsAjlstb9eH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a10713d-b9c7-4d99-d9f8-b9731d5eb157"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "#submission = (history, samples)\n",
        "#submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cP3d7Zv0b9eK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "JtB0oYcxb9eL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "OMHw5GJHb9eM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gCByGj49b9eP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "qp7mFmShb9eS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "Mw3ymz_Lb9eV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K0RDLzDwWQAm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
