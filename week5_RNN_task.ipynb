{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of RNN-task.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitaRamo/deep_learning_coursera/blob/master/week5_RNN_task.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "LAZmZTpIb9cZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Generating names with recurrent neural networks\n",
        "\n",
        "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
        "\n",
        "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
        "\n",
        "It's dangerous to go alone, take these:"
      ]
    },
    {
      "metadata": {
        "id": "O2ivZKXkc_ub",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ed7f4491-46a3-4ad1-e9e5-fdd95fe3b8eb"
      },
      "cell_type": "code",
      "source": [
        "! shred -u setup_google_colab.py\n",
        "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
        "import setup_google_colab\n",
        "# please, uncomment the week you're working on\n",
        "# setup_google_colab.setup_week1()\n",
        "# setup_google_colab.setup_week2()\n",
        "# setup_google_colab.setup_week3()\n",
        "# setup_google_colab.setup_week4()\n",
        "setup_google_colab.setup_week5()\n",
        "# setup_google_colab.setup_week6()\n",
        "\n",
        "# If you're using the old version of the course (check a path of notebook on Coursera, you'll see v1 or v2),\n",
        "# use setup_week2_old()."
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-12-27 14:55:56--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3792 (3.7K) [text/plain]\n",
            "Saving to: ‘setup_google_colab.py’\n",
            "\n",
            "\rsetup_google_colab.   0%[                    ]       0  --.-KB/s               \rsetup_google_colab. 100%[===================>]   3.70K  --.-KB/s    in 0s      \n",
            "\n",
            "2018-12-27 14:55:56 (50.3 MB/s) - ‘setup_google_colab.py’ saved [3792/3792]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.696201Z",
          "start_time": "2018-08-13T20:26:38.104103Z"
        },
        "id": "OxjXzyq_b9cf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0f2fd174-90c1-463e-8782-add3140ec3df"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "import keras_utils\n",
        "import tqdm_utils"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jCwORD3Ub9cn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load data\n",
        "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
        "\n",
        "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.701832Z",
          "start_time": "2018-08-13T20:26:42.697766Z"
        },
        "id": "-dK5iSs4b9cq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "start_token = \" \"  # so that the network knows that we're generating a first token\n",
        "\n",
        "# this is the token for padding,\n",
        "# we will add fake pad token at the end of names \n",
        "# to make them of equal size for further batching\n",
        "pad_token = \"#\"\n",
        "\n",
        "with open(\"names\") as f:\n",
        "    names = f.read()[:-1].split('\\n')\n",
        "    names = [start_token + name for name in names]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.707885Z",
          "start_time": "2018-08-13T20:26:42.703302Z"
        },
        "id": "dca-mF_qb9cv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d3cb87c5-8fd7-4e30-b084-50a9c7ccd813"
      },
      "cell_type": "code",
      "source": [
        "print('number of samples:', len(names))\n",
        "for x in names[::1000]:\n",
        "    print(x)"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples: 7944\n",
            " Abagael\n",
            " Claresta\n",
            " Glory\n",
            " Liliane\n",
            " Prissie\n",
            " Geeta\n",
            " Giovanne\n",
            " Piggy\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.857411Z",
          "start_time": "2018-08-13T20:26:42.709371Z"
        },
        "id": "LXvTFd-ab9c0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "a6343428-b81a-47e8-c801-15938c1e896f"
      },
      "cell_type": "code",
      "source": [
        "MAX_LENGTH = max(map(len, names))\n",
        "print(\"max length:\", MAX_LENGTH)\n",
        "\n",
        "plt.title('Sequence length distribution')\n",
        "plt.hist(list(map(len, names)), bins=25);"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "max length: 16\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEHCAYAAACgHI2PAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fca27c6ca58>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NrDd1EVHb9c4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Text processing\n",
        "\n",
        "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.864592Z",
          "start_time": "2018-08-13T20:26:42.858725Z"
        },
        "id": "AEvEjj2Vb9c6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb2fa9bd-eaa5-4cab-fe82-ba3e60a83542"
      },
      "cell_type": "code",
      "source": [
        "tokens = set(\" \".join(names)+pad_token) ### YOUR CODE HERE: all unique characters go here, padding included!\n",
        "\n",
        "tokens = list(tokens)\n",
        "n_tokens = len(tokens)\n",
        "print ('n_tokens:', n_tokens)\n",
        "\n",
        "assert 50 < n_tokens < 60"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n_tokens: 56\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e9QUTQ3Qb9c-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Cast everything from symbols into identifiers\n",
        "\n",
        "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
        "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
        "\n",
        "To create such dictionary, let's assign `token_to_id`"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.870330Z",
          "start_time": "2018-08-13T20:26:42.866135Z"
        },
        "id": "ToRr2VCFb9dA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "token_to_id =  dict(zip(tokens,range(n_tokens)))### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
        "\n",
        "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.875943Z",
          "start_time": "2018-08-13T20:26:42.871834Z"
        },
        "id": "0B_tzaoHb9dD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
        "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
        "    \n",
        "    max_len = max_len or max(map(len, names))\n",
        "    names_ix = np.zeros((len(names), max_len), dtype) + pad\n",
        "\n",
        "    for i in range(len(names)):\n",
        "        name_ix = list(map(token_to_id.get, names[i]))\n",
        "        names_ix[i, :len(name_ix)] = name_ix\n",
        "\n",
        "    return names_ix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:42.883107Z",
          "start_time": "2018-08-13T20:26:42.877186Z"
        },
        "id": "EXMxJx-kb9dH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "b619a6d6-36f6-4ab4-9350-705d5db9d259"
      },
      "cell_type": "code",
      "source": [
        "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
        "print('\\n'.join(names[::2000]))\n",
        "print(to_matrix(names[::2000]))"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Abagael\n",
            " Glory\n",
            " Prissie\n",
            " Giovanne\n",
            "[[ 0 20 54 25 32 25 11  6 33]\n",
            " [ 0 19  6 24 47 34 33 33 33]\n",
            " [ 0 31 47 29 48 48 29 11 33]\n",
            " [ 0 19 29 24  5 25  7  7 11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "nQylcwtzb9dN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Defining a recurrent neural network\n",
        "\n",
        "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
        "\n",
        "Since we're training a language model, there should also be:\n",
        "* An embedding layer that converts character id x_t to a vector.\n",
        "* An output layer that predicts probabilities of next phoneme based on h_t+1"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.039419Z",
          "start_time": "2018-08-13T20:26:42.884581Z"
        },
        "id": "Sl8b08Whb9dO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# remember to reset your session if you change your graph!\n",
        "s = keras_utils.reset_tf_session()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.044903Z",
          "start_time": "2018-08-13T20:26:44.041084Z"
        },
        "id": "QB5ZYJ1Bb9dT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.layers import concatenate, Dense, Embedding\n",
        "\n",
        "rnn_num_units = 64  # size of hidden state\n",
        "embedding_size = 16  # for characters\n",
        "\n",
        "# Let's create layers for our recurrent network\n",
        "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
        "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
        "\n",
        "# an embedding layer that converts character ids into embeddings\n",
        "embed_x = Embedding(n_tokens, embedding_size)\n",
        "\n",
        "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
        "get_h_next = Dense(rnn_num_units, activation=\"elu\")\n",
        "\n",
        "\n",
        "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
        "get_probas = Dense(n_tokens, activation=\"softmax\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fepr0outb9dW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "We will generate names character by character starting with `start_token`:\n",
        "\n",
        "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.053212Z",
          "start_time": "2018-08-13T20:26:44.048389Z"
        },
        "id": "QzJIY6pHb9dX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def rnn_one_step(x_t, h_t):\n",
        "    \"\"\"\n",
        "    Recurrent neural network step that produces \n",
        "    probabilities for next token x_t+1 and next state h_t+1\n",
        "    given current input x_t and previous state h_t.\n",
        "    We'll call this method repeatedly to produce the whole sequence.\n",
        "    \n",
        "    You're supposed to \"apply\" above layers to produce new tensors.\n",
        "    Follow inline instructions to complete the function.\n",
        "    \"\"\"\n",
        "    # convert character id into embedding\n",
        "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
        "    \n",
        "    # concatenate x_t embedding and previous h_t state\n",
        "    x_and_h = concatenate([x_t_emb, h_t] ,1)### YOUR CODE HERE\n",
        "    \n",
        "    # compute next state given x_and_h\n",
        "    h_next =  get_h_next(x_and_h) ### YOUR CODE HERE\n",
        "    \n",
        "    # get probabilities for language model P(x_next|h_next)\n",
        "    output_probas = get_probas(h_next)### YOUR CODE HERE\n",
        "    \n",
        "    return output_probas, h_next"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mTnzb-l7b9dc",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loop\n",
        "\n",
        "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
        "\n",
        "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.342948Z",
          "start_time": "2018-08-13T20:26:44.056136Z"
        },
        "id": "CsSyWhZfb9dd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
        "batch_size = tf.shape(input_sequence)[0]\n",
        "\n",
        "predicted_probas = []\n",
        "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
        "\n",
        "for t in range(MAX_LENGTH):\n",
        "    x_t = input_sequence[:, t]  # column t\n",
        "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
        "    \n",
        "    h_prev = h_next\n",
        "    predicted_probas.append(probas_next)\n",
        "    \n",
        "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
        "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
        "\n",
        "# next to last token prediction is not needed\n",
        "predicted_probas = predicted_probas[:, :-1, :]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OVqjLYVOb9dg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: loss and gradients\n",
        "\n",
        "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
        "\n",
        "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
        "\n",
        "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:44.354310Z",
          "start_time": "2018-08-13T20:26:44.344648Z"
        },
        "id": "Cqs2TS4xb9di",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# flatten predictions to [batch*time, n_tokens]\n",
        "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
        "\n",
        "# flatten answers (next tokens) and one-hot encode them\n",
        "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G1UL6ZZXb9dl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
        "\n",
        "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
        "\n",
        "For simplicity you can ignore this comment, it's up to you."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:45.076642Z",
          "start_time": "2018-08-13T20:26:44.355594Z"
        },
        "id": "Df8ONkFwb9dn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
        "# Mind that predictions are probabilities and NOT logits!\n",
        "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
        "\n",
        "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
        "### YOUR CODE HERE\n",
        "\n",
        "optimize = tf.train.AdamOptimizer().minimize(loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H8zt46mbb9dr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: training"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.322187Z",
          "start_time": "2018-08-13T20:26:45.078296Z"
        },
        "id": "dxO-VsZsb9dt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "outputId": "ac785315-4836-46dc-e00c-36beb079d98e"
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "from random import sample\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "batch_size = 32\n",
        "history = []\n",
        "\n",
        "for i in range(1000):\n",
        "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
        "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
        "    \n",
        "    history.append(loss_i)\n",
        "    \n",
        "    if (i + 1) % 100 == 0:\n",
        "        clear_output(True)\n",
        "        plt.plot(history, label='loss')\n",
        "        plt.legend()\n",
        "        plt.show()\n",
        "\n",
        "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
      ],
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fca0c70b6a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "luikiVIDb9d0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# RNN: sampling\n",
        "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.341196Z",
          "start_time": "2018-08-13T20:26:55.323787Z"
        },
        "id": "x1bDmygpb9d1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "x_t = tf.placeholder(tf.int32, (1,))\n",
        "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
        "\n",
        "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
        "# We reuse all parameters thanks to functional API usage.\n",
        "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
        "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
        "next_probs, next_h = rnn_one_step(x_t, h_t)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:55.346422Z",
          "start_time": "2018-08-13T20:26:55.342659Z"
        },
        "id": "Au0yOCFZb9d5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
        "    '''\n",
        "    This function generates text given a `seed_phrase` as a seed.\n",
        "    Remember to include start_token in seed phrase!\n",
        "    Parameter `max_length` is used to set the number of characters in prediction.\n",
        "    '''\n",
        "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
        "    s.run(tf.assign(h_t, h_t.initial_value))\n",
        "    \n",
        "    # feed the seed phrase, if any\n",
        "    for ix in x_sequence[:-1]:\n",
        "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
        "    \n",
        "    # start generating\n",
        "    for _ in range(max_length-len(seed_phrase)):\n",
        "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
        "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
        "        \n",
        "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:26:58.458115Z",
          "start_time": "2018-08-13T20:26:55.347900Z"
        },
        "id": "BOdV8eItb9d9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "9ee3b5bd-59e8-4cd8-a021-6d5d7f482929"
      },
      "cell_type": "code",
      "source": [
        "# without prefix\n",
        "for _ in range(10):\n",
        "    print(generate_sample())"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Nenilo\n",
            " Dardoy\n",
            " Jigy\n",
            " Mapfain\n",
            " Cichalna\n",
            " Nras\n",
            " Cerire\n",
            " Anthemna\n",
            " Erinre\n",
            " Semme\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:01.986726Z",
          "start_time": "2018-08-13T20:26:58.459810Z"
        },
        "id": "M0XXoPAHb9eA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "d4857b15-d99d-49aa-97f9-06164c9aa42a"
      },
      "cell_type": "code",
      "source": [
        "# with prefix conditioning\n",
        "for _ in range(10):\n",
        "    print(generate_sample(' Gui'))"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Guisqa\n",
            " GuifVo\n",
            " Guingea\n",
            " Guinta\n",
            " Guina\n",
            " Guica\n",
            " Guinaoa\n",
            " Guingdem\n",
            " Guil\n",
            " Guiny\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "FCDojRtAb9eD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Submit to Coursera"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:02.004926Z",
          "start_time": "2018-08-13T20:40:02.000821Z"
        },
        "id": "Zx09BHiHb9eE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# token expires every 30 min\n",
        "COURSERA_TOKEN = \"7yAtCj1NWECWCoTZ\"\n",
        "COURSERA_EMAIL = \"rita.mparada.ramos@gmail.com\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:40:18.923357Z",
          "start_time": "2018-08-13T20:40:03.549343Z"
        },
        "id": "qpsAjlstb9eH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "02bc8c78-92f2-4a4d-ed9f-ed00d2e732b7"
      },
      "cell_type": "code",
      "source": [
        "from submit import submit_char_rnn\n",
        "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
        "submission = (history, samples)$\n",
        "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
      ],
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "*************************\n",
            "\n",
            "Submitted to Coursera platform. See results on assignment page!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cP3d7Zv0b9eK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Try it out!\n",
        "\n",
        "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
        "\n",
        "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
        "\n",
        "* Novels/poems/songs of your favorite author\n",
        "* News titles/clickbait titles\n",
        "* Source code of Linux or Tensorflow\n",
        "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
        "* Melody in notes/chords format\n",
        "* IKEA catalog titles\n",
        "* Pokemon names\n",
        "* Cards from Magic, the Gathering / Hearthstone\n",
        "\n",
        "If you're willing to give it a try, here's what you wanna look at:\n",
        "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
        "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
        "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
        "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
        "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
        "\n",
        "__Good hunting!__"
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "JtB0oYcxb9eL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Bonus level: dynamic RNNs\n",
        "\n",
        "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
        "\n",
        "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
        "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
        "\n",
        "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.975354Z",
          "start_time": "2018-08-13T20:27:12.737529Z"
        },
        "id": "OMHw5GJHb9eM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "bb034fa2-18ff-4bb7-fde8-06ccb7d0b373"
      },
      "cell_type": "code",
      "source": [
        "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
        "    def call(self, input, state):\n",
        "        # from docs:\n",
        "        # Returns:\n",
        "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
        "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
        "        return rnn_one_step(input[:, 0], state)\n",
        "    \n",
        "    @property\n",
        "    def output_size(self):\n",
        "        return n_tokens\n",
        "    \n",
        "cell = CustomRNN(rnn_num_units)\n",
        "\n",
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "    \n",
        "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
        "\n",
        "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
        "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-125-5f3812e903bf>:13: BasicRNNCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.\n",
            "LSTM outputs for each step [batch,time,n_tokens]:\n",
            "(10, 50, 56)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gCByGj49b9eP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
        "\n",
        "You can also use any pre-implemented RNN cell:"
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:12.981697Z",
          "start_time": "2018-08-13T20:27:12.977590Z"
        },
        "id": "qp7mFmShb9eS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "040a6d9e-6a4b-4c26-c46b-d7d5ca2e213b"
      },
      "cell_type": "code",
      "source": [
        "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
        "    if obj.endswith('Cell'):\n",
        "        print(obj, end=\"\\t\")"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2018-08-13T20:27:13.168207Z",
          "start_time": "2018-08-13T20:27:12.986884Z"
        },
        "id": "Mw3ymz_Lb9eV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6fa6c267-d9e6-4948-c3dc-e20cf143652a"
      },
      "cell_type": "code",
      "source": [
        "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
        "\n",
        "inputs_embedded = embed_x(input_sequence)\n",
        "\n",
        "# standard cell returns hidden state as output!\n",
        "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
        "\n",
        "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
        "\n",
        "s.run(tf.global_variables_initializer())\n",
        "\n",
        "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
        "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "LSTM hidden state for each step [batch,time,rnn_num_units]:\n",
            "(10, 50, 64)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}